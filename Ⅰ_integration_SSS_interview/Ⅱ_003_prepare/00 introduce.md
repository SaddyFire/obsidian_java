**自我介绍**

	面试官好, 我叫王迪, 我是安徽淮南人, 19年毕业从事java行业到现在, 上家公司是南京丰数汇智科技有限公司,因为家人在杭州浙一工作, 想来杭州发展.  
	之前我们公司主要是针对于南京的一些中小型企业提供服务的一个平台,我们公司主要有大数据部门,有java研发部门,安卓部门,我是在java研发部门,我在里面主要负责的一些事情是代码的编写,需求文档的编写, 参与一些场景的解决方案讨论,以及前后端的联调对接工作.
	我在这家公司参过6个项目,最近一个项目叫趣读书,这个趣读书是针对在校大学生以及比较喜欢看书的人群, 给他们提供一个社区平台,形势上有点类似各个手机里面自带的社区功能,同时有一些类似公众号里的自媒体,可以发布文章到app里,普通用户可以制作自己的读书笔记库, 分享自己的个人心得; 也可以进行日常生活的点滴记录, 和互相间的私信、交流。正在拓展业务也包括即将支持书店的入驻, 用户也可以进行二手物品的交易买卖等.
	我们项目分为八个模块, 用户登录模块, 圈子模块, 消息模块, 二手交易模块, 个人信息模块,自媒体模块,后台管理模块, 前台页面展示模块, 我主要做的是个人信息展示模块, 圈子模块,后台管理模块,异常处理模块.

一个项目组的话是 前端2个, 后端5-6个, 2个移动,1个测试

`@RequestHeader`

##### 项目介绍
我们项目的整个后端架构以SpringBoot + Mybatis作为系统架构, RabbitMQ作中间件, Redis作缓存技术, FastDFS系统做小视频的数据存储,  MongoDB做海量数据的存储,  geo实现地理位置的查询, SpringCloud用的是二代Alibaba,GateWay作网关,  Nacos做服务发现注册中心和配置中心

我主要负责的是个人信息展示模块, 圈子模块,后台管理模块.


圈子模块分为个人的关注和推荐, 牵扯到一些关于个人动态的数据文件

这里首先是数据库的选择, 因为对于社交类软件来说, 他的特点是随着时间会积累越来越多的用户, 并且圈子动态的特点也是海量, 读多写少, 数据价值量相比较低, 以及还有类似发布位置上的特殊要求, 最后我们是选择mongoDB作为存储介质. 
首先核心表是好友表, 动态表 和 时间线表, 
*关注表*：记录单项或者双向好友关系
*动态详情表*：完整圈子动态内容
*时间线表*：记录用户，好友，动态的关联关系
发布动态会在动态表和时间线表存储, 查询的时候会根据这三张表查询动态并且根据时间倒叙展示

**具体实现**:
2. Service数据封装
	1. 调用API查询好友动态详情数据
	2. 调用API查询动态发布人详情
	3. 构造VO对象
3.API层根据用户ID查询好友发布动态详情
	1. 查询好友时间线表
	2. 查询动态详情

动态查询包含三个部分
1. 个人动态（已实现）
2. 好友动态
3. 操作用户查看所有好友发布的动态内容
4. 推荐动态, 趣读书平台接入大数据系统，根据个人喜欢实时计算出感兴趣的动态内容
表结构

![[Pasted image 20220219154308.png]]
   

**简单工厂**
我负责的个人信息展示模块在我的个人详情页里面有展示自己的几个按钮, 不同按钮前端会传不同**类型参数type** , 根据参数调用service层接口到库里取值,去数据库里做不同不同查询和各自的封装.
在这里我是用了做了一个简单工厂, sevice注入工厂, 通过工厂判断参数的不同, 去实例化我这几个业务对象, 然后在这几个对象去执行不同业务的操作. 这么做我就达到了在我service层几大块业务的强耦合. 如果日后有新增或删减的展示需求, 那我就只需要再去定义新的业务对象, 在里面写自己的代码, 主业务里只要多加一个if else即可


**Redis**
*hash*
平台通用功能主要是就是一些动态的展示, 动态评论,好友动态之类, 当中有一个是查询好友动态, 里面有个查询是动态评论点赞数, 这种低重要的数据, 我们是把这个点赞数同时是存到了redis里面方便读取, 用的hash结构, key存动态id, value存用户id, hashvalue存点赞数, 后续在操作数据库

*set*
在查看别人的信息展示页里有关注业务, 如果双方都关注的话会自动填加好友, 这里也是用了redis中的set , 防止重复, 谁关注谁会按前后方向存用户信息, 然后后续会用**mq**去异步去判断能不能添加好友的业务

*string*
后台管理模块的冻结用户, 在业务中首先去redis中找是否有当前用户的冻结信息, 有抛异常, 没有就根据参数设置冻结时间, 但是redis的失效时间要自己定义方法去计算冻结时间, 这里用的是string



**MQ**
在后台管理模块, 我做了用户行为日志的数据统计.
因为考虑到用户的操作是一系列的, 在各个模块下面, 
所以在这里我们是选择了mq进行一个异步请求, 把事件发布到mq里, 管理后台系统拿到最新消息, 构造日志数据存到数据库里
具体实现是要用户系统发送消息到MQ交换机路由, 然后LogListener绑定队列, 配置交换机信息, 指定routingKey
在这里我是用的aop去收集日志:
大致思路使首先使前置通知完成消息发送
然后做了个自定义注解`@LogConfig`
定义了个切面`LogAspect`, 切面里面写我的日志发送业务.
封装数据转JSON, 调用``mqtemplate``的``convereAndSend()``发到交换机里

**mq的重复性消费问题**
在传msg的时候要考虑到mq的一个重复性消费问题, 我是通过加入一个全局唯一的UUID
后台管理这边接受到数据的时候, 要先从redis里面查一下有没有这个UUID, 没有的话才进行消费, 并且把UUID存入redis

通过这种方式别人可以不改动代码添加注解快速实现这个功能



**mq的可靠性**
在这里还有一个问题, 就是关于mq的一个消息可靠性问题,首先思路是对mq丢消息的三种情况要做一个防护.

首先第一点是业务层丢数据, 这时候我们有两种解决方案, 
1. 一个是mq本身提供的事务功能, 就是生产者发送数据之前开启mq的事务（channel.txSelect），然后发送消息，如果消息没有成功被mq接收到，那么生产者这边会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是当时考虑到，rabbitmq这种事务机制, 他是一种同步的操作, 生产者这边发送个请求会同步阻塞卡住等待是成功还是失败, 会导致我们发消息这个吞吐量下来. 
2. 我们采用了第二种方案, 先把mq的channel设置成confirm的模式, 这样的话rabbitmq如果接收到消息, 就会回调我生产者本地的接口, 通知说已经收到消息. 如果rabbit在接收消息报错了, 会回调接口,告诉我们接收失败了, 可以再次重发 
    ![[Pasted image 20220218213615.png]]


生产者端之后, 还要保证mq不会把数据搞丢, 这时候就要开启rabbitmq的持久化, 消息写入之后会持久化到磁盘, 就是哪怕我mq自己挂了, 回复之后会自动读取之前存储的数据, 一般数据不会丢, 除非是及其罕见的事, rabbitmq还没持久化, 自己就挂了, 这种情况会导致少量数据会丢失, 但是概率比较小

*设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。*

并且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。
哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。

最后一个的话就是消息到了消费者这里, 但是还没来得及处理挂了, 但是mq会以为已经把消息处理完了, 
这里是我们要在消费者把mq里的一个autoAck关掉, 然后每次确定处理完消息过后再发送ack给rabbitmq

如果还没处理完就宕机, 这时候mq会把这条消息
![[Pasted image 20220218221230.png]]



##### 模块

我做的是**异常处理模块。** 自定义统一异常处理1、通过注解，声明异常处理类@ControllerAdvice2、编写方法，在方法内部处理异常，构造响应数据3、方法上编写注解，指定此方法可以处理的异常类型@ExceptionHandler。

项目中可能存在不可预知的各种异常，如：空指针，数组越界等。针对这类异常，可以直接在异常处理器中统一处理； 还有一类是可预知的错误，如图片不合法，验证码错误等等。这类错误也可以理解为业务异常，可以通过自定义异常类来处理；

捕获到非自定义异常类型首先从Map中找该异常类型是否对应具体的错误代码，如果有则取出错误代码和错误信息并响应给用户，如果从Map中找不到异常类型所对应的错误代码则统一为99999错误代码并响应给用户。将错误代码及错误信息以Json格式响应给用户。

接下来是圈子部分的视频的发布及其点赞、收藏、评论模块。 对于视频的发布及其点赞、收藏、评论的数据库我们使用了**MongoDB**，因为它支持海量数据的存储，可以很好的水平扩容虽然它不能像传统的关系型数据库那样进行多表联合查询，但对我们的业务而言单表操作足够了。（了解MongoDB中有哪些数据表）。 然后发布的小视频考虑到容量和费用的问题，我们团队没有选择第三方组件，选择了**FastDFS**。FastDFS是分布式文件系统。搭建是由我们老大搭建的。 然后考虑到如果有多人同时发动态，会产生**多线程**，因而我们将用户的动态id保存到所有好友的时间线表中这一步使用了**异步线程池**，使用@Async注解 实现。（将需要异步执行的代码抽取成独立的方法，在方法上使用@Async标注该方法是一个异步调用方法，在项目启动引导类上开启异步支持@EnableAsync)

点赞：首先需要判断一下是否已经点赞过了，如果没有就继续执行，将点赞的数据存储到MongoDB中，为了高效的 查询状态，将点赞状态存储到Redis中，在存储时使用的是Hash结构进行存储。String hashKey = Constants.MOVEMENT_LOVE_HASHKEY + movementId; String key = Constants.MOVEMENTS_INTERACT_KEY + movementId; redisTemplate.opsForHash().put(key,hashKey,"1"); 小key应该是点赞的人

即时通讯模块就使用环信第三方服务，使用它提供的sdk来实现。

运营数据展示模块：将用户的操作行为发送到写入RabbitMQ中，消息队列异步消费将记录写入数据库，后期做大数据分析用。

审核模块： 为了解决程序间耦合关系，这里采用RabbitMQ + 阿里云完成内容审核。 用户发布动态视频时，保存到数据库， 发送RabbitMQ消息，管理后台监听消息，对内容（文本、图片审核）， 更新动态的状态。



**文章的审核**
因为自媒体号发布的东西会涉及一些敏感话题, 这种就必须要进行审核, 审核过后才能让移动端查看.
审核方式主要有两种方式, 一种是自动审核, 文章发布之后, 系统会自动审核, 主要是通过第三方接口对文章内容(文本、图片内容)进行审核, 会反馈结果(成功、失败、不确定)
如果返回不确定的话就会调用第二种方式进行人工审核, 有后台管理员进行审核.
自动审核的话会有自媒体的微服务和文章的微服务, 文章微服务. 自媒体发布过后他的状态是提交待审核, 首先第一步是查询自媒体文章, 这时候调用阿里云提供的文本审核接口, 第二部是图片审核, 从FastDFS中拿取图片进行审核, 如果审核通过最后保存app端的相关数据

*将文章分为了文章信息表, 文章配置表(是否转发, 是否下架, 是否可评论, 是否删除),文章内容表*

这里的话因为考虑到随着业务的增长,文章表可能要占用很大的物理存储空间, 为了解决这个问题, 后期使用数据库分片技术, 将数据库进行拆分, 通过数据库中间件连接. 

如果数据库的表选用ID自增策略, 就有可能产生重复的ID, 此时的话我们采用了分布式ID生成策略来生成ID
当时我们考虑了三种技术选型, reids里面有一个全局连续递增的数字类型主键, 但是这种方案增加了一个组件, 考虑到redis要是挂了, 整个数据库就不能在插入了,
第二种方案是UUID, 但是考虑到他的字符组成太大了, 
最后我们采取的是雪花算法, 能保证全局唯一, 并且是数字类型, 存储成本也比较低, 缺点是机器的规模要小于1024.

在这里文章微服务发送文章后采用的是异步调用后台的进行审核, 采用的是springboot集成的异步线程调用

*1.在自动审核的方法上加上`@Async`注解
2.在文章发布成功后用审核的方法
3.在自媒体引导类中使用@EnableAsync注解开启异步调用*

这里还考虑到一个问题, 文章审核要过滤一些敏感词, 关于广告, 贷款之类的, 所以这里我们通过讨论还要自己维护一些敏感词, 不能完全指望第三方的审核, 这里我们当时也是有几套方案
第一个是数据库的模糊查询, 但是这种方法效率太低了
第二个是全文的检索, 类似es这种进行分词再匹配, 但是也是要集成新的一个系统
最后我们选择的是DFA算法, 我们导入了一套敏感词库表, 然后用工具类去进行计算
*DFA算法本质是map,isEnd=0说明没结尾,siEnd=1说明结尾了*

然后还有敏感图片的过滤, 我们用的是OCR技术, 也是有几个备选方案
1. 百度OCR
2. Google Tesseract-OCR引擎
3. Tess4J, 这是封装了Tesseract-OCR


##### Redis的缓存场景


##### Object的方法
getClass(),toString(),equal(),hashcode()



##### Http做了哪些处理
如果你发现了网站很卡,怎么排查
是不是我们服务器问题, 比如CPU, 内存, 硬盘, I/O, 网络宽带的话

**设计一下java的学习目录**
我关注过一个GitHub一个项目, 
关于一个程序员进阶之路的
首先是为什么要学习, 你的这套方案的一个亮点, 解决了什么问题, 还有介绍下java啊, 搭建啊, 基础之类的啊
ReadMe
然后是一个学习的架构


##### 购物车模块





##### 老牟
我主要参与的有登录鉴权模块，异常处理模块，圈子模块，即时通讯，运营数据展示模块，审核模块。 首先说一下**登录鉴权**模块。 用户在登录成功后系统会生成token，这个token就是采用**JWT**生成的。 **Jwt优点** 1），减轻服务端压力。 2），查询效率比token高。 3），不容易 **区别：** token需要查库验证token 是否有效，而JWT不用查库或者少查库，直接在服务端进行校验，并且不用查库。被客户端篡改数据。 JWT 的**原理**是，服务器认证以后，生成一个 JSON 对象，发回给用户。 **解释：** JWT就是一个字符串，是一个经过加密处理与校验处理的字符串，形式为：A.B.C，其中，A是JWT头部信息header加密得到的，B是JWT用到的身份验证信息json数据加密得到，C是A和B加密得到，是校验部分。所以，只要确保加密方式不会泄漏，就可以确保C部分是不会被人伪造的，通过这种方式确保了token的安全性。 **扩展：** 至于加密方式，一般来说会有2种方式，分别是：对称加密、非对称加密。一般而言，对称加密相对比较简单，但是其密钥泄露的风险比较高，而非对称加密，分为公钥和私钥，一般只要确保私钥不被泄漏就可以保证其安全性，所以非对称加密的泄漏风险要低一些。我们选择的就是用非对称加密进行计算C部分。 然后当用户再次进入网关开始访问的时候，网关过滤器会接受用户携带的token，然后解析TOKEN ，判断是否有权限，如果有，则放行，如果没有则返回未认证错误。 （自定义注解）

但这里有遇到问题。**问题和解决：** 1.首先，客户端收到服务器返回的 JWT，可以储存在 Cookie 里面， 然而我们微服务之间的调用是需要跨域的，（不需要跨域） 然而一个网页，只能操作当前域名下的cookie，，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。可以使用@RequestHeader("Authorization") String token。需要注意的是后台系统页面发送的token以"Bearer "开头，需要处理。 2.但是这样的话，每一个控制方法中都需要解析token , 获取当前用户id , 代码重复度比较高。我们是使用基于ThreadLocal（线程局部变量）+ 拦截器的形式统一处理。 ![[Pasted image 20220216110525.png]]

然后我做的是**异常处理模块。** 自定义统一异常处理1、通过注解，声明异常处理类@ControllerAdvice2、编写方法，在方法内部处理异常，构造响应数据3、方法上编写注解，指定此方法可以处理的异常类型@ExceptionHandler。

项目中可能存在不可预知的各种异常，如：空指针，数组越界等。针对这类异常，可以直接在异常处理器中统一处理； 还有一类是可预知的错误，如图片不合法，验证码错误等等。这类错误也可以理解为业务异常，可以通过自定义异常类来处理；

捕获到非自定义异常类型首先从Map中找该异常类型是否对应具体的错误代码，如果有则取出错误代码和错误信息并响应给用户，如果从Map中找不到异常类型所对应的错误代码则统一为99999错误代码并响应给用户。将错误代码及错误信息以Json格式响应给用户。

接下来是圈子部分的视频的发布及其点赞、收藏、评论模块。 对于视频的发布及其点赞、收藏、评论的数据库我们使用了**MongoDB**，因为它支持海量数据的存储，可以很好的水平扩容虽然它不能像传统的关系型数据库那样进行多表联合查询，但对我们的业务而言单表操作足够了。（了解MongoDB中有哪些数据表）。 然后发布的小视频考虑到容量和费用的问题，我们团队没有选择第三方组件，选择了**FastDFS**。FastDFS是分布式文件系统。搭建是由我们老大搭建的。 然后考虑到如果有多人同时发动态，会产生**多线程**，因而我们将用户的动态id保存到所有好友的时间线表中这一步使用了**异步线程池**，使用@Async注解 实现。（将需要异步执行的代码抽取成独立的方法，在方法上使用@Async标注该方法是一个异步调用方法，在项目启动引导类上开启异步支持@EnableAsync)

点赞：首先需要判断一下是否已经点赞过了，如果没有就继续执行，将点赞的数据存储到MongoDB中，为了高效的 查询状态，将点赞状态存储到Redis中，在存储时使用的是Hash结构进行存储。String hashKey = Constants.MOVEMENT_LOVE_HASHKEY + movementId; String key = Constants.MOVEMENTS_INTERACT_KEY + movementId; redisTemplate.opsForHash().put(key,hashKey,"1"); 小key应该是点赞的人

即时通讯模块就使用环信第三方服务，使用它提供的sdk来实现。

运营数据展示模块：将用户的操作行为发送到写入RabbitMQ中，消息队列异步消费将记录写入数据库，后期做大数据分析用。

审核模块： 为了解决程序间耦合关系，这里采用RabbitMQ + 阿里云完成内容审核。 用户发布动态视频时，保存到数据库， 发送RabbitMQ消息，管理后台监听消息，对内容（文本、图片审核）， 更新动态的状态。


