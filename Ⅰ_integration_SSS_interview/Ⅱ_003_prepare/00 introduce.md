**自我介绍**

	面试官好, 我叫王迪, 老家是安徽淮南的, 上家公司是南京丰数汇智科技有限公司,因为家人在杭州浙一工作, 想来杭州发展.  
	之前我们公司主要是针对于南京的一些中小型企业提供服务的一个平台,我们公司主要有大数据部门,有java研发部门,安卓部门,我担任的是java研发部门,我在里面主要负责的一些事情是代码的编写,需求文档的编写, 有时候会参与一些场景的一些解决方案 ,以及前后端的联调对接工作.
	我在这家公司做过6个项目,最近一个项目叫趣读书,这个趣读书是针对南京,滁州,马鞍山地区的一些大学生以及比较喜欢看书的人群, 给他们提供一个交流平台,形势上有点类似华为手机和小米手机里面的花粉俱乐部和小米社区,我们的这些用户同时呢也可以分享自己的生活, 照片, 视频, 帖子等,正在拓展业务有书店的入驻, 也可以进行二手书的交易买卖.
	我们技术栈用的是市场比较主流的组件, 像springboot,springcloud, redis,mq啊都有涉及,我个人对这些技术点也比较熟悉, 我们项目分为七个模块, 用户登录模块, 圈子模块, 消息模块, 二手交易模块, 个人信息模块,自媒体模块,后台管理模块, 前台页面展示模块, 我主要做的是个人信息展示模块, 圈子模块,后台管理模块.

一个项目组的话是 前端2个, 后端5-6个, 2个移动,1个测试

`@RequestHeader`

##### 项目介绍
我们项目的整个后端架构以SpringBoot + Mybatis作为系统架构, RabbitMQ作中间件, Redis作缓存技术, FastDFS系统做小视频的数据存储,  MongoDB geo实现地理位置的查询, SpringCloud用的是二代Alibaba,GateWay作网关,  Nacos做服务发现注册中心和配置中心, 分布式远程调用时用的Dubbo. 
在这里我们springcloudAlibaba用的2.2.5, dubbo用的是2.7.8, 这两个版本的nacos和dubbo微服务调用的情况下时有时候会造成冲突, 如果是只重启dao层的情况下之后进行调用会报9000错误.



圈子动态查询
动态查询包含三个部分
1. 个人动态（已实现）
2. 好友动态
3. 操作用户查看所有好友发布的动态内容
4. 推荐动态, 趣读书平台接入大数据系统，根据个人喜欢实时计算出感兴趣的动态内容
表结构
好友表：记录单项或者双向好友关系
动态详情表：完整圈子动态内容
时间线表：记录用户，好友，动态的关联关系
![[Pasted image 20220219154308.png]]
   
1. Controller层接受请求参数
2. Service数据封装
	1. 调用API查询好友动态详情数据
	2. 调用API查询动态发布人详情
	3. 构造VO对象
3.API层根据用户ID查询好友发布动态详情
	1. 查询好友时间线表
	2. 查询动态详情



这里首先是数据库的选择, 因为对于社交类软件来说, 他的特点是随着时间会积累越来越多的用户, 并且圈子动态的特点也是海量, 读多写少, 数据价值量相比较低, 以及还有一些位置上的特殊要求, 最后我们是选择mongoDB作为存储介质. 
首先核心表是


**文章的审核**
因为自媒体号发布的东西会涉及一些敏感话题, 这种就必须要进行审核, 审核过后才能让移动端查看.
审核方式主要有两种方式, 一种是自动审核, 文章发布之后, 系统会自动审核, 主要是通过第三方接口对文章内容(文本、图片内容)进行审核, 会反馈结果(成功、失败、不确定)
如果返回不确定的话就会调用第二种方式进行人工审核, 有后台管理员进行审核.
自动审核的话会有自媒体的微服务和文章的微服务, 文章微服务. 自媒体发布过后他的状态是提交待审核, 首先第一步是查询自媒体文章, 这时候调用阿里云提供的文本审核接口, 第二部是图片审核, 从FastDFS中拿取图片进行审核, 如果审核通过最后保存app端的相关数据

*将文章分为了文章信息表, 文章配置表(是否转发, 是否下架, 是否可评论, 是否删除),文章内容表*

这里的话因为考虑到随着业务的增长,文章表可能要占用很大的物理存储空间, 为了解决这个问题, 后期使用数据库分片技术, 将数据库进行拆分, 通过数据库中间件连接. 

如果数据库的表选用ID自增策略, 就有可能产生重复的ID, 此时的话我们采用了分布式ID生成策略来生成ID
当时我们考虑了三种技术选型, reids里面有一个全局连续递增的数字类型主键, 但是这种方案增加了一个组件, 考虑到redis要是挂了, 整个数据库就不能在插入了,
第二种方案是UUID, 但是考虑到他的字符组成太大了, 
最后我们采取的是雪花算法, 能保证全局唯一, 并且是数字类型, 存储成本也比较低, 缺点是机器的规模要小于1024.

在这里文章微服务发送文章后采用的是异步调用后台的进行审核, 采用的是springboot集成的异步线程调用

*1.在自动审核的方法上加上`@Async`注解
2.在文章发布成功后用审核的方法
3.在自媒体引导类中使用@EnableAsync注解开启异步调用*

这里还考虑到一个问题, 文章审核要过滤一些敏感词, 关于广告, 贷款之类的, 所以这里我们通过讨论还要自己维护一些敏感词, 不能完全指望第三方的审核, 这里我们当时也是有几套方案
第一个是数据库的模糊查询, 但是这种方法效率太低了
第二个是全文的检索, 类似es这种进行分词再匹配, 但是也是要集成新的一个系统
第三种是DFA算法, 导入了一套敏感此表, 然后用
*DFA算法本质是map,isEnd=0说明没结尾,siEnd=1说明结尾了*






**简单工厂**
我负责的个人信息展示模块在我的个人详情页里面有展示自己的几个按钮, 不同按钮前端会传不同**类型参数type** , 根据参数调用service层接口到库里取值,去数据库里做不同不同查询和各自的封装.
在这里我是用了做了一个简单工厂, sevice注入工厂, 通过工厂判断参数的不同, 去实例化我这几个业务对象, 然后在这几个对象去执行不同业务的操作. 这么做我就达到了在我service层几大块业务的强耦合. 如果日后有新增或删减的展示需求, 那我就只需要再去定义新的业务对象, 在里面写自己的代码, 主业务里只要多加一个if else即可

**Redis**
*hash*
平台通用功能主要是就是一些动态的展示, 动态评论,好友动态之类, 当中有一个是查询好友动态, 里面有个查询是动态评论点赞数, 这种低重要的数据, 我们是把这个点赞数同时是存到了redis里面方便读取, 用的hash结构, key存动态id, value存用户id, hashvalue存点赞数, 后续在操作数据库

*set*
在查看别人的信息展示页里有关注业务, 如果双方都关注的话会自动填加好友, 这里也是用了redis中的set , 防止重复, 谁关注谁会按前后方向存用户信息, 然后后续会用**mq**去异步去判断能不能添加好友的业务

*string*
后台管理模块的冻结用户, 在业务中首先去redis中找是否有当前用户的冻结信息, 有抛异常, 没有就根据参数设置冻结时间, 但是redis的失效时间要自己定义方法去计算冻结时间, 这里用的是string



**MQ**
在后台管理模块, 我做了用户行为日志的数据统计.
因为考虑到用户的操作是一系列的, 在各个模块下面, 
所以在这里我们是选择了mq进行一个异步请求, 把事件发布到mq里, 管理后台系统拿到最新消息, 构造日志数据存到数据库里
具体实现是要用户系统发送消息到MQ交换机路由, 然后LogListener绑定队列, 配置交换机信息, 指定routingKey
在这里我是用的aop去收集日志:
大致思路使首先使前置通知完成消息发送
然后做了个自定义注解`@LogConfig`
定义了个切面`LogAspect`, 切面里面写我的日志发送业务.
封装数据转JSON, 调用``mqtemplate``的``convereAndSend()``发到交换机里

**mq的重复性消费问题**
在传msg的时候要考虑到mq的一个重复性消费问题, 我是通过加入一个全局唯一的UUID
后台管理这边接受到数据的时候, 要先从redis里面查一下有没有这个UUID, 没有的话才进行消费, 并且把UUID存入redis

通过这种方式别人可以不改动代码添加注解快速实现这个功能



**mq的可靠性**
在这里还有一个问题, 就是关于mq的一个消息可靠性问题,首先思路是对mq丢消息的三种情况要做一个防护.

首先第一点是业务层那边丢了数据, 他那边再调用mq可能在半路数据搞丢了, 这时候我们有两种解决方案, 
1. 一个是mq本身提供的事务功能, 就是生产者发送数据之前开启mq的事务（channel.txSelect），然后发送消息，如果消息没有成功被mq接收到，那么生产者这边会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是当时考虑到，rabbitmq这种事务机制, 他是一种同步的操作, 生产者这边发送个请求会同步阻塞卡住等待是成功还是失败, 会导致我们发消息这个吞吐量下来. 
2. 我们采用了第二种方案, 先把mq的channel设置成confirm的模式, 发送一个消息, 之后就不用管了, rabbitmq如果接收到了这条消息的话, 就会回调我生产者本地的接口, 通知说已经收到消息. 如果rabbit在接收消息报错了, 会回调接口,告诉我们接收失败了, 可以再次重发 
    ![[Pasted image 20220218213615.png]]


生产者端之后, 我还要保证mq不会把数据搞丢, 这时候就要开启rabbitmq的持久化, 消息写入之后会持久化到磁盘, 就是哪怕我mq自己挂了, 回复之后会自动读取之前存储的数据, 一般数据不会丢, 除非是及其罕见的事, rabbitmq还没持久化, 自己就挂了, 这种情况会导致少量数据会丢失, 但是概率比较小

*设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。*

并且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。
哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。

最后一个的话就是消息到了消费者这里, 但是还没来得及处理挂了, 但是mq会以为已经把消息处理完了, 
这里是我们要在消费者把mq里的一个autoAck关掉, 然后每次确定处理完消息过后再发送ack给rabbitmq

如果还没处理完就宕机, 这时候mq会把这条消息
![[Pasted image 20220218221230.png]]

##### Redis的缓存场景




##### Object的方法
getClass(),toString(),equal(),hashcode()



##### Http做了哪些处理
如果你发现了网站很卡,怎么排查
是不是我们服务器问题, 比如CPU, 内存, 硬盘, I/O, 网络宽带的话

**设计一下java的学习目录**
我关注过一个GitHub一个项目, 
关于一个程序员进阶之路的
首先是为什么要学习, 你的这套方案的一个亮点, 解决了什么问题, 还有介绍下java啊, 搭建啊, 基础之类的啊
ReadMe
然后是一个学习的架构


##### 购物车模块




