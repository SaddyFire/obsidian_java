##### HashMap
![[Pasted image 20220213195738.png]]
	
	首先hashmap是一种**key-value**键值对形式的集合, 在1.7之前他的底层是数组加链表, 1.8之后他的底层是数组, 链表和红黑树. 
	在把**数据存入**hashmap中时, 会先通过该数据key的hash值进行哈希函数, 类似于对数字的取模取余, 如果得到的角标位置已经有数据了, 也就是hash冲突, 此时会以链表的形式挂下来.
	在1.7之前, 如果链表过长,就会导致每次查询要一个个撸下来, 而1.8之后采用红黑树方式的查询效率就会大大提高. 但是数据少的时候树的结点大小比链表要大, 所以在一个哈希桶数量大于8的时候才会变为红黑树, 小于6的时候会转回链表. 
	还有一点是1.7的hashmap是**头插法,速度快**,但是在多线程并发和数组扩容的时候会出现循环列表, 导致死锁问题, 所以在1.8之后的红黑树用尾插法, 能相对避免死锁. 在项目中的话, 如果有并发需求, 我们通常会采用concurrentHashmap, 他的底层是对hashmap的哈希桶上锁, 达到多线程安全.
	




##### 多线程_四大线程池

newSingleThreadExecutor
newFixedThreadPool
newCachedThreadPool
newScheduledThreadPool

##### 多线程_线程池七大参数
- 核心线程数
- 最大线程数
- 临时线程最大存活时间
- 时间单位
- 等待队列
- 创建线程工厂
- 任务拒绝策略

##### 多线程_ThreadLocal
threadlocal是一个线程内部的存储类，提供了线程内存储变量的能力,可以在指定线程内存储数据，数据存储以后，只有指定线程可以得到存储数据。这些变量不同之处在于每一个线程读取的变量是对应的互相独立的。

其内部维护了一个ThreadLocalMap，该Map用于存储每一个线程的变量副本。并且key为线程对象，value为对应线程的变量副本。


##### JVM_介绍下JVM
JVM提供了java程序在不同的系统上运行可能
![[Pasted image 20220220184623.png]]
jvm是指**Java virtual Machine**, 在一个**class文件加载**到java虚拟机中, 要经历loading , linking, initializing, 
其中首先虚拟机要将class文件load进classloader, 加载器会通过**双亲委派模型**, 从costumclassloader到appClassloader最终到bootstrap, 这样做的根本原因是是为了安全, 防止底层类库被篡改.同时如果经过了双亲委派模型最后也没找到该类, 则会报**classnotfound**异常. class文件load进内存之后会进行verification,preparation和resolution,进行字节码文件的解析, **initializing**是对静态变量的初始化赋值.

每个线程运行的时候都会在栈中开辟一块空间 而栈中的方法运行或对象创建时会在这个栈中开辟一块空间叫 栈贞

##### 内存空间
**方法区**`(Method Area)`：是各个**线程共享的区域，存储类结构信息**的地方，包括**常量池、静态变量、构造函数等**

**Java堆`(Heap)`**：也是**线程共享的区域，存储`Java`实例或者对象的地方。** 这里`GC`的主要区域。堆的内存空间既可以固定大小，也可以在运行时动态地调整。通过参数`-Xms(memory start)`和`-Xmx(memory max)`来进行设置。如果二者设置一样，则堆内存被固定。

**Java栈`(Stack)`**：**每个线程私有的区域，它的生命周期与线程相同**每执行一个方法就会往栈中压入一个元素，这个元素叫**栈帧**，**用于存储局部变量表、操作栈、方法返回值等**。

**本地方法栈`(Native Method Stack)`**：和`Java`栈类似，只不过是为`JVM`使用到的`native`方法服务的。

**程序计数器`(PC Register)`**：**每个线程私有的区域，用于保存当前线程执行的内存地址。**由于`JVM`程序是多线程执行的（线程轮流切换），所以**为了保证线程切换回来后，还能恢复到原先状态**，就需要一个独立的计数器，记录之前中断的地方。



##### JVM_JMM
JMM就是Java内存模型(java memory model)。因为在不同的硬件生产商和不同的操作系统下，**内存的访问**有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。所以java内存模型(JMM)**屏蔽掉各种硬件和操作系统的内存访问差异**，以实现让java程序在各种平台下都能达到一致的并发效果

JMM是抽象概念, main memory 和 working memory
多个线程大家一块用的内存叫主内存, 在物理结构中叫堆heap
但是每个线程各自操作数据的时候, 会有一个各自的working memory , 操作的是从主内存中拷贝过来的副本, 所有操作是要在自己的工作内存进行



##### JVM_GC
假设一个场景, Student s1 = new Student();
Student s2 = new Student();
这个时候刚才的Student()对象就没有别人的指引, 也叫野指针,
java包含了编译型和解释型语言
垃圾回收器分为: 新生代 + 老年代 + 永久代（1.7）Perm Generation/ 元数据区(1.8) Metaspace
新生代 是 Eden + 2个suvivor区
第一次扫描garbage的时候新生代回收之后, 大多会被回收, 活着的就进入suvivor0
再次扫描, 或者的从eden 和s0 进入s1
再次扫描, eden 和s1 会重新进入s0
当达到一定程度之后, 会进入老年代

常见的GC回收器:
Serial 和 SerialOld
现在默认的回收器是Parallel Scavenge 和Parallel Old
ParNew和CMS
再后来就是GI

**GC算法**
1、标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。

2、复制算法：按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉。缺点：内存使用率不高，只有原来的一半。

3、标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。

4、分代算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法，老年代采用标记整理算法。


##### JVM_volatile关键字
volatile可以保证多线程之间数据的**可见性**和**一定有序性**,  因为变量被volatile修饰过后, 当这个数据要进行写操作, JVM会发送一条**lock指令**给CPU,CPU计算完数据之后会立刻把这个数据写回到主内存, 而且**mesi协议**会分别给每个线程各自的这个数据都打标记, 例如你的modify就是我的invalid, 如果有invalid标记那我就会回到主内存去读数据

1.  **保证线程间变量的可见性。**
2.  **禁止CPU进行指令重排序。**

##### JVM_JVM调优
-**Xmx3350m**: 设置JVM最大可用内存为3550M
-**Xms3350m**: 设置JVM初始内存为3550M
-Xmn2g: 设置年青代大小为2g 整个JVM内存大小=年青代+ 老年代+ 持久代大小, sum官方推荐配置整个堆的3/8
-Xss256k: 设置每个线程的栈大小, 根据应用线程所需要的内存大小调整, 满足需要的情况下, 越小能产生更多的线程

##### JVM_垃圾回收算法
1. 标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。

2. 复制算法：按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉。缺点：内存使用率不高，只有原来的一半。

3. 标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。

4. 分代算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法，老年代采用标记整理算法。

##### JVM_OOM怎么处理
情景: 
1. 一般的排查方式可以通过设置-XX: +HeapDumpOnOutOfMemoryError在发生异常时dump出当前的内存转储快照来分析
2. IDEA2018版本之后内置了分析工具


写集合时候，忘了内部回收，长时间的积累，造成内部泄露。
物理解决，增加交换区，增加内存条，提高超时时间，java 的话可以稍微提高一下堆内存和静态区的内存。以上治标不治本，最好的方法是用一些性能监视工具 java 的可以用 jstack 等等，来监控是哪个线程或者进程占用内存或 cpu 过多，有针对性的对代码调优从根本上解决 OOM 异常。


##### Spring动态代理
jdk动态代理和cglib的区别
jdk是接口, cglib是继承类. jdk是通过反射, cglib是通过字节码



##### Spring的理解
spring广义上来说是一个完整的生态, spring对项目的开发有超强的**拓展性**,spring家族让开发进入了春天时代. 侠义的spring框架核心主要是ioc和aop, ioc是指inversion of control 也就是控制反转, 本质是一种思想, 是一种程序之间的解耦思想,将对象的创建权力反转给spring. ioc也是工厂模式, 单例模式, 模板方法, 观察者设计模式的一种实现. 


##### Spring的bean生命周期
首先spring是一个轻量级框架, 帮我们简化开发, 核心功能是ioc和aop
**bean的生命周期只是ioc创建对象的一个流程**,里面大体来说可以包含实例化, 初始化, 使用, 销毁
如果说细粒度的的话, 通过反射的方式读取到`beandefinition`的相关信息,把这些对象创建出来, 然后通过反射的方式加载类, 创建对象, 此时的创建只是在堆内存中申请了一块内存空间, 
所以此时的值只是默认值,接下来会通过一个方法, 叫`populateBean()`方法来给当前属性赋值, 会调用相应set()方法完成属性的赋值, 但是这部分只会完成自定义属性的操作, 还有一部分属性叫做容器属性, 是spring框架给我们定义的自定义对象, 所以这时候还会调用一个`aware()`接口, 通过这个接口可以帮我们判断是否能进行属性值的设置工作, 所以相当于populatebean()和`invokeAwareMethods()`方法都完成了属性的赋值工作, 一个是自定义属性的赋值, 一个是容器属性的赋值, 当这个时候完成之后, 正常情况下bean对象已经可以正常使用了.
但是这里spring设计的时候考虑到了一个特点, 比如拓展性, 当bean对象创建过后可能会对bean对象有一些扩展的过程, 比如aop的实现, 其实就是对我们生成的bean对象有一定的拓展操作, `PostProcessor`接口里面有after()before()方法来进行增强, aop的底层动态代理也是在这里实现的
当这些步骤都完成之后, 就可以完成bean的创建了, 这是我可以通过Context.getBean()来调取.
当最后关闭容器的时候, 会调用close()方法, 把对象销毁掉
![[Pasted image 20220215163227.png]]
![[Pasted image 20220215163013.png]]

##### Spring_factorybean 和 beanfactory
beanfactory是spring容器的入口, 定义了一系列的接口规范, 对象的创建经过一个完整的复杂生命周期过程, 可以说是一种流水线的工作流程

factorybean更像是一种定制化, 可以自己定义FactoryBean来实现Bean的特殊要求, 自己可以自定义, 不需要完全遵循bean的生命周期

##### Spring循环依赖的/三级缓存
循环依赖是指A对象里有个属性是b, B对象里有个属性是a,
**先捋一下循环依赖的流程**
此时这是一个**闭环问题**, 如果要解决这个问题我们要想, 从形成环的那个步骤把这个闭环干掉
这里我们可以定义一个概念: 按照对象的状态进行分类, 分为**成品, 半成品**, 一个是完成品和半成品
所以这是我就可以再闭环链路的判断容器是否有A或者B的那个节点打开, 虽然没有成品, 但是有半成品, 有地址值
还有一个概念是三级缓存, 就是三个map结构, 就是说我前面说的一旦我初始化A或者B, 我就立刻把这个半成品对象放到map里, 那这个时候在每次判断我有没有A或者B的时候, 我都有了半成品, 这个环一走, 我都能进行赋值
所以其实本质上最后能解决循环依赖问题的, 是spring的生命周期中, 实例化和初始化时分开的
![[Pasted image 20220215224553.png]]

##### 接口抽象类的差别
- 接口: 自上向下: 定义空方法, 空约束,先定义规范,然后实现具体方法
- 抽象类: 自下向上: 我已经现有n种不同的子类, 然后抽取公共部分


##### SpringMVC的加载过程
SpringMVC是指spring module view controller, 也叫模型视图控制器, 把web层进行解耦, 简化开发
首先springMVC的入口是DispatcherServlet(`package org.springframework.web.servlet`)前端控制器, 其中有核心方法`initStrategies()`初始化了映射处理器, `doDispatch() `处理请求方法, 并且获取到`HandlerAdapter`, 也就是处理器适配器, 最终调用了后端处理器`handle()`方法处理请求, 并返回`ModelAndView`模型视图

##### SpringBoot的自动配置/SPI机制
首先SPI 是Service Provider Interface, 是一种服务发现机制, springboot的底层也使用到了spi机制
`@SpringBootApplication`  -> `@EnableAutoConfiguration` -> `@import` 中导入的类会被加载到spring IOC容器中 ->  最终会被spring反射调用`classLoader`类中的的getResourcees() 把`META-INFO`下的`spring.factories`文件里的类load进jvm


##### MySQL
首先mysql是一个**关系型数据库**, 关系型数据库和nosql在本质的区别是一个偏于存储硬盘, 一个偏于存储在内存, 因为是基于硬盘存储.
mysql的**存储引擎**, 在mysql5.5之后, 默认引擎改成了innodb, 之前是myisom, 存储引擎是一种**存储数据文件的形式**, 源文件里面innodb是2个, myisom是3个, 因为innodb采用了聚簇索引的方式, 他们两个底层都是b+树, 但是innodb把行数据放在了b+树的**叶子节点**. myisom的磁盘块放的是指针和数据行的地址. 
因为有了聚簇索引这里有牵扯到一个概念叫回表, B+树的聚簇索引表一定会有一张, 可以是主键, 可以是唯一键, 如果都没有就会默认给你生成一个6字节的rowid, 所以比方`select * from xx where name='zhangsan'` 如果我name是索引, 那我会先在name索引表里查到这行数据的聚簇索引id, 然后再回聚簇索引里查这个行数据. 讲到这又有一个索引覆盖, 就是我不回表, 直接从name里面查id 和name, 这样就不用回表


##### MySQL的事务
首先mysql 的 事务是关系型数据库和nosql数据库的根本区别, 它可以用来维护数据操作的安全, 能够保证一系列操作的要么完全成功, 要么完全失败
事务的四大特性是**ACID**, mysql中只有innodb是支持事务的

##### MySQL_事务的隔离级别
4种。
1. 读未提交（RU：read uncommitted）：可能存在【脏读+不可重复读+幻读】的问题。
2. 读已提交（RC：read committed）：可能存在【不可重复读+幻读】问题。
3. 可重复读（RR：repeatable read）：可能存在【幻读】问题。
4. 序行化（serializable）：无以上问题，但效率低，一务在分布式事务的情况下用该级别。

**脏读**(Drity Read)：是指在一个事务处理过程中读取了另一个未提交的事务中的数据 , 导致两次查询结果不一致。

 

**不可重复读**(Non-repeatable read)【MySQL默认】:事务开启后关闭前，多次读取同一条记录，结果却不能保证一致，所以叫不可重复读。主要问题不在同一个数据库的问题，而在不同的服务器，不同数据库时会出现的问题，因为两台电脑之间要保证数据相同，是需要时间进行复制的，从表在复制主表的过程中，很可能因为修改数据过快而导致复制到错误数据。

 

**幻读**(Phantom Read):select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入。或不存在执行delete删除，却发现删除成功。


##### MySQL优化
正如上图所示，数据库优化可以从架构优化，硬件优化，DB优化，SQL优化四个维度入手。此上而下，位置越靠前优化越明显，对数据库的性能提升越高。我们常说的SQL优化反而是对性能提高最小的优化。
**架构优化**: 一般来说在高并发的场景下对架构层进行优化其效果最为明显，常见的优化手段有：分布式缓存，读写分离，分库分表等，每种优化手段又适用于不同的应用场景。

****

##### MySQL数据库优化
1.  数据表优化, 磁盘块每个磁盘块大小16kb, 表中的主键要越小越好, 因此主键用varchar和int, 如果数据小于4个字节, 用varchar, 大于4个字节, 用int  
2. 在满足需求的情况下,尽量主键自增, 因为这样在插入数据时不会对B+树中的磁盘块分裂
3. 使用前缀索引(通过索引的选择性来构建索引), 可以让b+树存储更多的数据, 口语说是索引长度要适当取值

##### MySQL语句的优化
首先关于mysql数据优化之前,我们要明确mysql的常用几种数据存储引擎, 在mysql5.5之后, 默认的存储引擎是innodb, innodb的底层
-   `select * from actor where actor_id = 1 or actor_id = 2`  
    `select * from actor where actor_id in (1,2)`  
    `select * from actor where actor_id = 1 union all select * from actor where actor_id = 2`  
    union all or 都能使用索引, 推荐使用in, union会分两步执行  
    or单列索引可以走, 组合索引不会走,所以推荐in
	
- `select id from t where num in(1,2,3)` 对于连续的数值, 能用between就不用in select id from t where num between 1 and 3
-  `select id from t where num/2=100` 应改为: `select id from t where num=100*2` 避免表字段尽量不要用表达式, 把计算放到业务层, 这会导致直接放弃索引
- 范围列都可以用索引 范围条件是:  但是只能用一个范围
- `select * from user where phone = 123`  
    `select * from user where phone='123'`  
    强制类型转换会全表扫描
- 更新十分频繁, 数据区分度不高的字段上不建议建立索引, 因为数据库要维护,类似于性别类区分不大的属性,建立索引没有意义, 不能有效过滤数据, 区分度在80%以上可以建立



##### MySQL索引语句创建
create index 索引名 on 表名(列名)

##### MySQL_表锁行锁
乐观锁: 
使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。
	即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。
	当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。        
	update … where … and version=”old version”
	当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
悲观锁: 
1. mySQL的表锁有两种模式：读锁（Table Read Lock）和写锁（Table Write Lock）
2. 当一个线程获得对一个表的写锁后，只有持有锁线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止

`select * from user where id = 1 for update   [使用了悲观锁,行锁]`
`select * from user  for update               [使用了悲观锁,表锁]`

总结:查询一条数据的时候加悲观锁就叫行锁
     查询整张表或者某个范围的时候加悲观锁就叫表锁[在修改某一条数据的时候,也会锁住整个表]
     
    
 场景:小公司,手动操作数据库,实施工程师/DBA     

##### MySQL的三范式
第一范式：保证每列的原子性 -> **数据库表中的所有字段值都是不可分解的原子值**
第二范式：保证一张表只描述一件事情 -> 
第三范式----保证每列都和主键直接相关


##### RabbitMQ使用场景
关注好友里面如果相互关注的话是会默认添加好友, 业务里是要额外查一下双方是否相互关注, 我是把加好友加到mq里了, 因为之前做过一个业务, 也是类似这种模式, 当时

##### RabbitMQ避免重复消费
我通常的做法是

 
##### RabbitMQ保证顺序性
![[Pasted image 20220218225417.png]]
只要保证需要按顺序执行的消息在一个队列


##### RabbitMQ消息延时&过期失效


##### 高并发怎么处理
![[Pasted image 20220215193256.png]]
首先要提前预估用户的并发量
1. **微服务架构拆分**
2. **800-1000个请求**(读请求)先用缓存, 把页面浏览的信息用minIO或者redis抗压,这些主要是用来读的一些属性, 可以数据库写一份, 缓存写一份, 大量请求直接先到缓存
3. **1500-2000个请求**写请求 -> 用mq异步处理,这是为了处理消峰, 消峰一过, 再快速的把这个请求消化掉, 如果说还是消化不掉, 进行分库分表, 每个库承担压力
4. **1500-2000个请求**这种情况下, 如果缓存失效, 缓存又会有定时的写缓存, 这时候要进行数据库读写分离主库, 缓存从从库里单独去读数据
5. 如果是搜索请求, 一开始数据量很小, 可以自己基于lucene包封装搜索引擎, 如果数据量越来越大的话, 单机lucene撑不了这么搞得并发, 这时候要用es分布式集群, 因为es本身就是分布式, 加上他的存储海量数据的特性

##### 分布式CAP
C	Consistency
A	Availability
P	Partition Tolerance


##### 分布式事务
**TCC方案** 
比如A账户给B账户转钱, 
Try阶段: 先把两个银行账户中的资金冻结住
Confirm: A减钱 和 B加钱, 如果中间
Cancel阶段: 如果任何一个账户操作失败, 就要回滚进行补偿
但是这种方案业务耦合太多, 每个业务的try, confirm, cancel都不一样, 所以只有跟钱相关的分布式事务, 要么全部成功, 要么全部自动回滚, 严格保证资金的正确性, 用TCC方案, 维护难

**本地消息表方案**
EBAY的方案
也是A调用B的方案, A/B自己系统都有自己的业务表和消息表,A和B的业务和消息都有各自的事务, A系统操作业务后会插入数据到消息表, 然后通过MQ调用B, B会先在消息表里插入数据, 同时要设置消息表建一个唯一约束, 这样可以通过幂等来保证事务唯一性, 等到排除这种重复消费过后, 进行业务处理. 
这时候A和B中间要用到zookeeper去监听唯一键的值, 反馈给A, 成功就大家都成功了, 如果B,如果失败了, A系统的消息表就一直有待确认, 如果超时间了就重复发送MQ

这种问题是他大量依赖数据库里的消息表, 所以没办法解决高并发的情况
![[Pasted image 20220216133301.png]]
**可靠消息最终一致性方案**
A系统会先发送prepared消息到RocketMQ, 如果本地事务OK, 就给MQ发送confirm消息确认, 如果失败了, 就回滚prepared消息.
B系统是如果收到了confirm, B系统会消费消息
但是入宫A系统发送失败了, 消息停在prepared状态, MQ就会自动轮询prepared消息, 而且他会回调A系统的接口, 是回滚这个消息还是重新发送.这时候就由业务去选择
但是如果B失败了, 也是可以通过监听, 让A回滚, 但是这种方案B系统一定要保证他的幂等性
这是最终一致性方案
![[Pasted image 20220216134000.png]]

任何一个分布式事务方案, 都会导致代码复杂10背.通常情况下, 系统A调用B, 系统C, 系统D, 根本不会做分布式事务, 如果调用报错会打印异常

99%分布式接口调用, 不要做分布式事务, 直接就是监控,记录日志,事后快速的定位、排查和和出解决方案、修复数据。

##### Redis高并发的原理
1. Redis的末端的内部事件处理器是纯内存操作

2. 核心是基于非阻塞的IO多路复用机制, 他中间有个队列, 那个队列只负责排列一下消息, 不会造成一个阻塞

3. 单线程反而避免了多线程的频繁上下文切换问题（百度）



##### Redis分布式事务锁
首先redis是一种nosql, 是为了解决海量数据走数据库会很容易崩塌的这种问题, **Redis有5种主要数据类型**：string、hash、list(有序、可重复)、set(无序、不可重复)、zset(不可重复，基于score实现排序)
Redis之所以读取速度快是因为他基于内存操作,数据结构key-value相对简单,单线程操作不会有cpu上下文的切换,多路的I/O复用

Redis分布式锁的加锁, 本质上是加一个key,value，其实就是给Key键设置一个值（SET lock_key random_value NX PX 5000，NX表示键不存在时才设置），其他进程执行前会判断Redis中这个Key是否有值，如果发现这个Key有值了，就说明已有其他进程在执行，则循环等待，超时则获取失败
锁信息一定要设置过期时间, 不然万一要是redis挂了就会成死锁了

##### Redis持久化
redis限定了总内存大小只能存1g, 一开始的话redis会通过LRU缓存清除算法 ,redis持久化主要是防止redis没了, 通过RDB和AOF两种机制能把redis数据持久化到磁盘, 然后再将这些数据备份到别的地方去, 如果redis挂了, 可以从云服务器拷贝数据
**RDB:** Redis Database Backup file
也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。

**AOF:** Append Only File(追加文件)  -->  AOF主要是放一个个的写命令, 写os cache, 所以他会不断地膨胀, 当到一定程度, 他就会做rewrite操作, 就是根据当时redis内存数据, 重新构造一个更小的aof文件, 把之前老的文件删了

##### Redis_缓存穿透、缓存雪崩、缓存击穿？
**缓存穿透**是指反复查询不存在的数据, 导致数据库压力过大, 这是恶意. 比如说每次系统从数据库只要没查到,就写一个空值到缓存里, 下次的话就能给他返回了
**缓存雪崩**指某一个时间段内, 缓存集中的过期失效, 导致大量请求过来, 压力都集中到数据库, 过期时间设置随机值, 同时我可以用sentinel来设置限流一部分, 降级方案
**缓存击穿**指将一个热点key的redis缓存失效, 导致大量请求瞬间集中到数据库

##### Redis_缓存和数据库一直性
初级: 先删缓存, 每次修改数据库的时候再回头存缓存. 这种情况下如果数据库出错没改成功, 那缓存再去读一下, 把数据库的值再读一下

第二种: 再更新一个库存的时候, 同时在读取这个库存的时候, 并发的发生了, 这个时候, 还是会出现数据库和缓存双写不一致情况
比如我库存1000的, 修改的那一瞬间, 
![[Pasted image 20220219111331.png]]

##### Linux 常用命令
tail -f test.log  循环查看
head -n 10 test.log 查询日志文件前多少行
cat 是从第一行到最后一行连续显示在屏幕上

clear
pwd
cd
ls -a
mv
touch
mkdir
rm -f
cp
top 当前cup的使用信息
free 

##### 常用压力测试软件
JMeter / QPS

##### git分区
工作区, add. 缓存区, 版本区

##### Maven版本依赖冲突问题
idea里面插件maven helper插件, 点开pom.xml会有一个Dependency Analyzer视图


##### MyBatisPlus_里批量添加
有两种, 基础的是saveBatch, 但是这种底层就是循环添加, 另一种是要加一个插件, 通过这个插件可以调一个方法insertBatchSomeColumn, 底层是把你批量添加的数据打了个包, 然后分批写sql语句

##### 工厂模式, 抽象工厂模式
工厂方法模式就是多个工厂, 再让工厂去创建对象
工厂方法模式的工厂是创建出**一种产品**，而抽象工厂是创建出**一类产品**。


##### 策略模式

页面存储时间, 前端传页面时间, 

